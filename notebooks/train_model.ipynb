{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ca435f554dec474392c01f726698a2cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ebca6d8d18d4f3da3e3714a58e080d6","IPY_MODEL_37d6e1e6d7a34793aba7ba8198706bad","IPY_MODEL_2317c20105b74166bde288f5a5703e56"],"layout":"IPY_MODEL_36a3d177b2d841de95ee706251ec2302"}},"9ebca6d8d18d4f3da3e3714a58e080d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d53f02e02bac4abeac1003c88d32f0c7","placeholder":"​","style":"IPY_MODEL_3b146980fda54ab0af4489e778aacda0","value":"tokenizer_config.json: 100%"}},"37d6e1e6d7a34793aba7ba8198706bad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_849649fb92214c1ca4b3af452ccf4090","max":59,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f12aff2530c4cf6bf28f86d91f81b79","value":59}},"2317c20105b74166bde288f5a5703e56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4031e69ed30e46169604a8e5c2c9592e","placeholder":"​","style":"IPY_MODEL_16110f5ab9fb4ed7a2972d43c9c3a4df","value":" 59.0/59.0 [00:00&lt;00:00, 501B/s]"}},"36a3d177b2d841de95ee706251ec2302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d53f02e02bac4abeac1003c88d32f0c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b146980fda54ab0af4489e778aacda0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"849649fb92214c1ca4b3af452ccf4090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f12aff2530c4cf6bf28f86d91f81b79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4031e69ed30e46169604a8e5c2c9592e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16110f5ab9fb4ed7a2972d43c9c3a4df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aa6fac1e2f6454baedad884a68c98c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e91f469dfa8447d8f72a746606623b7","IPY_MODEL_901b618aecb748cd973bf22742f89059","IPY_MODEL_88884cb3d1894e59989f4255f0b70bb7"],"layout":"IPY_MODEL_92c077b0bb2841a5812efe6000b4b29c"}},"4e91f469dfa8447d8f72a746606623b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_724f02f93b734f24a4409767b83c6e2f","placeholder":"​","style":"IPY_MODEL_db97cbde555d477f8a82163aa3d9e68f","value":"config.json: 100%"}},"901b618aecb748cd973bf22742f89059":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_411f63891f0a4367bd6265be26b21f2d","max":829,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff2f90ad10574b9c8e4c39d4196b346b","value":829}},"88884cb3d1894e59989f4255f0b70bb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72d370e27d924e2193d0caf002bd76cb","placeholder":"​","style":"IPY_MODEL_127a0ba726c9492a80dc6866c95a2e39","value":" 829/829 [00:00&lt;00:00, 8.63kB/s]"}},"92c077b0bb2841a5812efe6000b4b29c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"724f02f93b734f24a4409767b83c6e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db97cbde555d477f8a82163aa3d9e68f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"411f63891f0a4367bd6265be26b21f2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff2f90ad10574b9c8e4c39d4196b346b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72d370e27d924e2193d0caf002bd76cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"127a0ba726c9492a80dc6866c95a2e39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"816033946ada4e93849101ecbdfa34ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48758c84828e4d97a15d6591c3ff9e7a","IPY_MODEL_ee2a5503d81543fa94d05b019078128d","IPY_MODEL_8ad9fecf864244aab800fad16a33f0b9"],"layout":"IPY_MODEL_0bca82829a234110b52fe7e5f1f4225e"}},"48758c84828e4d97a15d6591c3ff9e7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_466af605926c40028544d2d9c704d14a","placeholder":"​","style":"IPY_MODEL_877878be16ee4962b9038854306a40c4","value":"vocab.txt: 100%"}},"ee2a5503d81543fa94d05b019078128d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d620e16407294eb9bdbea3b8e47b20a7","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fb418c88d1a4f48a0035e916ab5304f","value":213450}},"8ad9fecf864244aab800fad16a33f0b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b87b3067e579430a9b31db6c2bac0d8f","placeholder":"​","style":"IPY_MODEL_b7f2865f024e4eb49bbf10d877adca80","value":" 213k/213k [00:00&lt;00:00, 2.31MB/s]"}},"0bca82829a234110b52fe7e5f1f4225e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"466af605926c40028544d2d9c704d14a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"877878be16ee4962b9038854306a40c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d620e16407294eb9bdbea3b8e47b20a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fb418c88d1a4f48a0035e916ab5304f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b87b3067e579430a9b31db6c2bac0d8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7f2865f024e4eb49bbf10d877adca80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b672d12eae244c16a38e9091d96e3329":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de4adaae307d4523992dc3283a54a6bf","IPY_MODEL_d4f5d87177274e4cb2dde8dadab4eb81","IPY_MODEL_61c83b8a3b8b41e588771f8e3c274798"],"layout":"IPY_MODEL_84fbf40694b64cccabdb93ff28a0201c"}},"de4adaae307d4523992dc3283a54a6bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfdb0cd7c6a24d858f08057963cbab55","placeholder":"​","style":"IPY_MODEL_069ffdb137674023acabe66e3a7e932b","value":"added_tokens.json: 100%"}},"d4f5d87177274e4cb2dde8dadab4eb81":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b7cd1de492e474eb14c3dc4b7c75893","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83ef564a3af141c49ca638b5d6f12df5","value":2}},"61c83b8a3b8b41e588771f8e3c274798":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cfda5a0b6fe45c8b97f3f98d2ccf153","placeholder":"​","style":"IPY_MODEL_3bef003eb22043cb9820cc5ab1b0da5d","value":" 2.00/2.00 [00:00&lt;00:00, 29.9B/s]"}},"84fbf40694b64cccabdb93ff28a0201c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfdb0cd7c6a24d858f08057963cbab55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"069ffdb137674023acabe66e3a7e932b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b7cd1de492e474eb14c3dc4b7c75893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83ef564a3af141c49ca638b5d6f12df5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cfda5a0b6fe45c8b97f3f98d2ccf153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bef003eb22043cb9820cc5ab1b0da5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1018133c74cf428fa46bcf06995dd8b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1d26999a6b24ef6af7e8e4389818ed4","IPY_MODEL_c753393a10a44362ade1a68439842562","IPY_MODEL_335f3b7943cf477e831fe70810ea6750"],"layout":"IPY_MODEL_5ec5547a1ea94af6abc5213f7e894491"}},"f1d26999a6b24ef6af7e8e4389818ed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0173e9bf7b5b4b82ad4954ed13620672","placeholder":"​","style":"IPY_MODEL_15d77346b87b4239b8a9e6f0fc0c77cb","value":"special_tokens_map.json: 100%"}},"c753393a10a44362ade1a68439842562":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e25d91284f14e94b01aea550825593e","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11dc9590348f4bccab899ea5728d182e","value":112}},"335f3b7943cf477e831fe70810ea6750":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5332119d39c94454bd58392993ff5bbe","placeholder":"​","style":"IPY_MODEL_7007b78754fc4f279997f0323cce7bb1","value":" 112/112 [00:00&lt;00:00, 1.19kB/s]"}},"5ec5547a1ea94af6abc5213f7e894491":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0173e9bf7b5b4b82ad4954ed13620672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15d77346b87b4239b8a9e6f0fc0c77cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e25d91284f14e94b01aea550825593e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11dc9590348f4bccab899ea5728d182e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5332119d39c94454bd58392993ff5bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7007b78754fc4f279997f0323cce7bb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9734246,"sourceType":"datasetVersion","datasetId":5957398}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**The entire code is being run in the Kaggle environment due to the need for a powerful GPU to train the model. In this section, we prepare the dataset for training, train the model, and evaluate its performance.**","metadata":{}},{"cell_type":"markdown","source":"Here, we prepare the dataset for model training, train the model, and evaluate its performance.","metadata":{}},{"cell_type":"markdown","source":"In this section, we install several libraries needed for model training and evaluation:\n\n- `bitsandbytes`: Optimizes memory usage for model training, especially useful when working with large models.\n- `wandb`: A tool for tracking and visualizing experiments in real-time, which helps in monitoring model performance during training.\n- `accelerate`: Facilitates distributed training, making it easier to leverage powerful GPUs on platforms like Kaggle.\n- `transformers[torch]` and `datasets`: Provided by Hugging Face, these libraries give access to pre-trained models and diverse datasets, streamlining the process of fine-tuning models on custom data.\n- `peft`: Enables parameter-efficient fine-tuning of large models, reducing computational costs while maintaining model quality.\n\nThese installations set up the necessary environment for the model preparation, training, and evaluation stages.","metadata":{}},{"cell_type":"code","source":"!pip install -U bitsandbytes\n!pip install wandb\n!pip install accelerate\n! pip install -q transformers[torch] datasets\n!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:20:37.220218Z","iopub.execute_input":"2024-10-27T19:20:37.221006Z","iopub.status.idle":"2024-10-27T19:21:36.223367Z","shell.execute_reply.started":"2024-10-27T19:20:37.220965Z","shell.execute_reply":"2024-10-27T19:21:36.221197Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Import the `wandb` library and log in to our Weights & Biases account using an API key.","metadata":{}},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"61f57d09a2c684e4990e098e51c337c27a650b02\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:36.225889Z","iopub.execute_input":"2024-10-27T19:21:36.226288Z","iopub.status.idle":"2024-10-27T19:21:36.236842Z","shell.execute_reply.started":"2024-10-27T19:21:36.226245Z","shell.execute_reply":"2024-10-27T19:21:36.235720Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"Initializing a new `wandb` run logs training progress in the \"mountain-recognition\" project. ","metadata":{}},{"cell_type":"code","source":"wandb.init(\n    # set the wandb project where this run will be logged\n    project=\"mountain-recognition\",\n\n    # track hyperparameters and run metadata\n    config={\n    \"learning_rate\": 0.02,\n    \"architecture\": \"transformer\",\n    \"dataset\": \"mountain_names_recognition\",\n    \"epochs\": 3,\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:36.238124Z","iopub.execute_input":"2024-10-27T19:21:36.238487Z","iopub.status.idle":"2024-10-27T19:21:39.508785Z","shell.execute_reply.started":"2024-10-27T19:21:36.238453Z","shell.execute_reply":"2024-10-27T19:21:39.507899Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:l1ktb05v) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rich-snow-19</strong> at: <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/l1ktb05v' target=\"_blank\">https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/l1ktb05v</a><br/> View project at: <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition' target=\"_blank\">https://wandb.ai/claire-zhuk-atom-space/mountain-recognition</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241027_191533-l1ktb05v/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:l1ktb05v). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241027_192136-bues1dcv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/bues1dcv' target=\"_blank\">valiant-water-20</a></strong> to <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition' target=\"_blank\">https://wandb.ai/claire-zhuk-atom-space/mountain-recognition</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/bues1dcv' target=\"_blank\">https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/bues1dcv</a>"},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/bues1dcv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ac0fe4d17e0>"},"metadata":{}}]},{"cell_type":"markdown","source":"The code defines a function to load CoNLL files into pandas DataFrames, facilitating the preparation of data for model training.\n\n- **`load_conll_file(file_path)`**: This function reads a CoNLL file and extracts tokens and their corresponding NER tags into two separate lists for each sentence. It creates a DataFrame with columns `tokens` and `ner_tags`, allowing for easy manipulation and analysis of the data.\n\n- **File Reading**: The function processes the file line by line, using empty lines to identify new sentences. If the file doesn’t end with an empty line, the last sentence's tokens and tags are also included.\n\n- **Loading Training and Testing Data**: The function is applied to the specified training and testing file paths, creating `train_coll` and `test_coll` DataFrames. This organization of data is crucial for effectively training and evaluating the model later in the project.\n\n- **DataFrame Structure Check**: The code includes commented-out lines to check the structure of the loaded DataFrames to ensure they are in the correct format for further processing.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Function to load a CoNLL file into a DataFrame\ndef load_conll_file(file_path):\n    tokens = []\n    ner_tags = []\n\n    # Reading the file line by line\n    with open(file_path, 'r', encoding='utf-8') as file:\n        current_sentence_tokens = []\n        current_sentence_tags = []\n\n        for line in file:\n            line = line.strip()\n            if not line:  # Empty line indicates a new sentence\n                if current_sentence_tokens:\n                    tokens.append(current_sentence_tokens)\n                    ner_tags.append(current_sentence_tags)\n                    current_sentence_tokens = []\n                    current_sentence_tags = []\n            else:\n                token, ner_tag = line.split()\n                current_sentence_tokens.append(token)\n                current_sentence_tags.append(ner_tag)\n\n        # Adding the last sentence if the file does not end with an empty line\n        if current_sentence_tokens:\n            tokens.append(current_sentence_tokens)\n            ner_tags.append(current_sentence_tags)\n\n    # Creating DataFrame with sentences\n    df = pd.DataFrame({'tokens': tokens, 'ner_tags': ner_tags})\n    return df\n\n# Apply function to the train and test files\ntrain_file_path = '/kaggle/input/mountains-names-recognition/train_file.conll'\ntest_file_path = '/kaggle/input/mountains-names-recognition/test_file.conll'\n\ntrain_coll = load_conll_file(train_file_path)\ntest_coll = load_conll_file(test_file_path)\n\n# Check if they are in the correct format\n# print(train_coll.head())\n# print(test_coll.head())","metadata":{"id":"2cgQK3zRNuip","execution":{"iopub.status.busy":"2024-10-27T19:21:39.510924Z","iopub.execute_input":"2024-10-27T19:21:39.511234Z","iopub.status.idle":"2024-10-27T19:21:39.587267Z","shell.execute_reply.started":"2024-10-27T19:21:39.511201Z","shell.execute_reply":"2024-10-27T19:21:39.586512Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"In this section, we prepare the dataset for training by defining unique NER tags and converting the data into a format suitable for model processing.\n\n- The `add_id` function is implemented to assign a unique identifier to each example in the dataset, which aids in tracking individual entries.\n\n- The `encode_ner_tags` function transforms the NER tags into their integer representations using a `ClassLabel` mapping, ensuring the model can process these tags effectively.\n\n- Unique NER tags are identified from both the training and testing datasets, creating a comprehensive set of labels for the model to recognize.\n\n- Finally, we convert the pandas DataFrames into datasets compatible with our model training framework, adding the unique IDs and encoding the NER tags accordingly. This preparation is essential for efficient training and evaluation of the model.","metadata":{}},{"cell_type":"code","source":"from datasets import ClassLabel, Dataset\n\ndef add_id(example, idx):\n    example[\"id\"] = str(idx)\n    return example\n\ndef encode_ner_tags(example):\n    example[\"ner_tags\"] = [ner_class_label.str2int(tag) for tag in example[\"ner_tags\"]]\n    return example\n\n# Define all unique labels (tags) in the dataset\nall_tags = set(tag for tags in train_coll[\"ner_tags\"] for tag in tags)\nall_tags.update(tag for tags in test_coll[\"ner_tags\"] for tag in tags)\n\n# Create ClassLabel for NER tags\nner_class_label = ClassLabel(names=list(all_tags))\n\ntrain_dataset = Dataset.from_pandas(train_coll)\ntest_dataset = Dataset.from_pandas(test_coll)\n\ntrain_dataset = train_dataset.map(add_id, with_indices=True)\ntest_dataset = test_dataset.map(add_id, with_indices=True)\n\n# Convert NER tags to ClassLabel format\ntrain_dataset = train_dataset.map(encode_ner_tags)\ntest_dataset = test_dataset.map(encode_ner_tags)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:39.588386Z","iopub.execute_input":"2024-10-27T19:21:39.588694Z","iopub.status.idle":"2024-10-27T19:21:40.483080Z","shell.execute_reply.started":"2024-10-27T19:21:39.588662Z","shell.execute_reply":"2024-10-27T19:21:40.482206Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37deb70d37714960b05dbf71822e5ea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/928 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94db2f838c7f4d4daea20cfb3468495d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c7307e409e4c769467d5d99ff549aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/928 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8538ab2c466a411d90a9cfd026dd6260"}},"metadata":{}}]},{"cell_type":"markdown","source":"Define the features of our datasets to ensure they are structured correctly for model training. The `Features` object specifies the structure, including sequences for `tokens` and `ner_tags`, along with a unique identifier `id`. The `cast` method is then applied to both the training and testing datasets to transform them according to this defined structure, ensuring consistency for training and evaluation.","metadata":{}},{"cell_type":"code","source":"from datasets import Sequence, Features, Sequence\nfeatures = Features({\n    'tokens': Sequence(feature=train_dataset.features['tokens'].feature),\n    'ner_tags': Sequence(feature=ner_class_label),\n    'id': train_dataset.features['id']\n})\n\ntrain_dataset = train_dataset.cast(features)\ntest_dataset = test_dataset.cast(features.copy())","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:40.484637Z","iopub.execute_input":"2024-10-27T19:21:40.485074Z","iopub.status.idle":"2024-10-27T19:21:40.545622Z","shell.execute_reply.started":"2024-10-27T19:21:40.485026Z","shell.execute_reply":"2024-10-27T19:21:40.544701Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/3716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cccb6254ac440ca8f706ad13dc8c435"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/928 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f90e4ab2d544b2ba5d1aff5b6210d76"}},"metadata":{}}]},{"cell_type":"markdown","source":"We load a pre-trained BERT tokenizer and model for Named Entity Recognition (NER). The `AutoTokenizer` prepares the text for input into the model, while `AutoModelForTokenClassification` initializes the NER model. Using the `\"dslim/bert-base-NER\"` model allows us to leverage existing training for efficient NER tasks, and setting `load_in_8bit=True` optimizes memory usage for model loading, enabling training on limited hardware.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\ntokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n\nner_model = AutoModelForTokenClassification.from_pretrained(\n    \"dslim/bert-base-NER\",\n    load_in_8bit=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:40.546685Z","iopub.execute_input":"2024-10-27T19:21:40.547006Z","iopub.status.idle":"2024-10-27T19:21:41.707920Z","shell.execute_reply.started":"2024-10-27T19:21:40.546974Z","shell.execute_reply":"2024-10-27T19:21:41.706917Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n`low_cpu_mem_usage` was None, now set to True since model is quantized.\nSome weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We implement a function to tokenize the dataset and align the NER labels accordingly. The `tokenize_and_align_labels` function uses the tokenizer to process the `tokens` field, ensuring that the inputs are properly prepared for the model. It handles special tokens and aligns the corresponding NER labels to the tokenized outputs, ensuring each token has the correct label or is marked as `-100` for tokens that don't correspond to any word.\n\nThe function is then applied to both the training and testing datasets in a batched manner for efficiency. Finally, we set the format of the datasets for PyTorch, specifying that the relevant columns (`input_ids`, `attention_mask`, and `labels`) should be formatted as tensors, enabling compatibility with the model during training.","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\n# Tokenize and align labels\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples['tokens'],\n        is_split_into_words=True,\n        truncation=True,\n        padding='max_length'  # or True for dynamic padding\n    )\n\n    labels = []\n    for i, label in enumerate(examples['ner_tags']):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        label_ids = []\n        previous_word_idx = None\n        for word_idx in word_ids:\n            if word_idx is None:\n                # Special tokens have no word index\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                # Label for the first token of the word\n                label_ids.append(label[word_idx])\n            else:\n                # Label for the subsequent tokens in a word\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\n# Apply the function to the datasets\ntrain_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\ntest_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n\n# Set the format for PyTorch tensors\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"id":"LuqLDwDVORWm","execution":{"iopub.status.busy":"2024-10-27T19:21:41.709220Z","iopub.execute_input":"2024-10-27T19:21:41.709541Z","iopub.status.idle":"2024-10-27T19:21:44.642979Z","shell.execute_reply.started":"2024-10-27T19:21:41.709508Z","shell.execute_reply":"2024-10-27T19:21:44.642083Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac6580e6cdb4aa29d5f4d5e4ebb41a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/928 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d59a0a0ffb214be1a777f9f7c27a6062"}},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can see model architecture","metadata":{}},{"cell_type":"code","source":"print(ner_model)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:44.644045Z","iopub.execute_input":"2024-10-27T19:21:44.644410Z","iopub.status.idle":"2024-10-27T19:21:44.652717Z","shell.execute_reply.started":"2024-10-27T19:21:44.644369Z","shell.execute_reply":"2024-10-27T19:21:44.651890Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear8bitLt(in_features=768, out_features=768, bias=True)\n              (key): Linear8bitLt(in_features=768, out_features=768, bias=True)\n              (value): Linear8bitLt(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear8bitLt(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear8bitLt(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear8bitLt(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=9, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We configure and fine-tune the NER model using LoRA (Low-Rank Adaptation) to improve performance while optimizing resource usage. The `LoraConfig` sets parameters such as rank, scaling, target layers, and dropout rate for the LoRA adapters.\n\nThe model is wrapped with these adapters, allowing for efficient training. A data collator is created to handle dynamic padding and batch formatting during training.\n\nA custom logging callback is defined to log the training loss to Weights & Biases (WandB) at specified intervals, enabling real-time monitoring of the training process.\n\nThe `train_model` function initializes the training arguments, including batch sizes, number of epochs, and logging settings. It then sets up a `Trainer` instance with the model, datasets, and the custom data collator, and begins the training process. The training function is executed to fine-tune the model on the provided datasets.","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\nfrom transformers import DataCollatorForTokenClassification, TrainingArguments, Trainer\nfrom transformers import TrainerCallback\n\n# Define LoRA configuration\nlora_config = LoraConfig(\n    r=4,  # LoRA rank\n    lora_alpha=32,  # Scaling parameter\n    target_modules=[\"query\", \"key\", \"value\"],  # Layers for LoRA\n    lora_dropout=0.1, # LoRA dropout rate\n)\n\n# Wrap the model with LoRA adapters\npeft_model = get_peft_model(ner_model, lora_config)\n\n# Create data_collator\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\nclass LoggingCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs and 'loss' in logs:\n            # Логування train_loss в WandB кожні logging_steps\n            wandb.log({\"train_loss\": logs[\"loss\"]})\n\n# Updated train_model function\ndef train_model(model, train_dataset, test_dataset):\n    \"\"\"Fine-tune a quantized model with LoRA adapters.\"\"\"\n    training_args = TrainingArguments(\n        remove_unused_columns=False,\n        output_dir='./kaggle/working/results',\n        num_train_epochs=3,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=128,\n        warmup_steps=100,\n        weight_decay=0.01,\n        logging_dir='./kaggle/working/logs',\n        fp16=False,  \n        logging_steps=50,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=test_dataset,\n        data_collator=data_collator,\n        callbacks=[LoggingCallback()]\n    )\n\n    trainer.train()\n\n# Run training function\ntrain_model(peft_model, train_dataset, test_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:21:44.662537Z","iopub.execute_input":"2024-10-27T19:21:44.662918Z","iopub.status.idle":"2024-10-27T19:30:46.720375Z","shell.execute_reply.started":"2024-10-27T19:21:44.662876Z","shell.execute_reply":"2024-10-27T19:30:46.719573Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='699' max='699' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [699/699 09:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>9.971900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>7.945000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.425200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.738100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.351800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.234700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.181800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.157600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.131600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.126600</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.098800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.088100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.085900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"We set up the model saving process by creating a directory to store the trained model and tokenizer on Kaggle. The `os.makedirs` function ensures that the directory is created if it doesn't already exist.\n\nThe trained LoRA model and the tokenizer are saved to the specified path, allowing for easy retrieval later. Additionally, the WandB configuration is saved in a YAML file, providing a record of the training settings used during the model's fine-tuning.\n\nTo facilitate downloading, we create a compressed ZIP archive of the saved model directory, making it easier to manage and transfer the files after training is complete.","metadata":{}},{"cell_type":"code","source":"import os\nimport yaml\n\n# Path to save the model on Kaggle\nmodel_save_path = \"/kaggle/working/trained_model\"\nos.makedirs(model_save_path, exist_ok=True)\n\n# Saving the model and tokenizer\npeft_model.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\n\n# Saving the W&B configuration in a YAML file\nconfig_path = os.path.join(model_save_path, \"wandb_config.yaml\")\nwith open(config_path, \"w\") as f:\n    yaml.dump(dict(wandb.config), f)\n\n# Creating an archive for easy downloading\n!zip -r /kaggle/working/trained_model.zip /kaggle/working/trained_model\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:30:46.727155Z","iopub.execute_input":"2024-10-27T19:30:46.727433Z","iopub.status.idle":"2024-10-27T19:30:48.046443Z","shell.execute_reply.started":"2024-10-27T19:30:46.727403Z","shell.execute_reply":"2024-10-27T19:30:48.045296Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"updating: kaggle/working/trained_model/ (stored 0%)\nupdating: kaggle/working/trained_model/special_tokens_map.json (deflated 42%)\nupdating: kaggle/working/trained_model/vocab.txt (deflated 49%)\nupdating: kaggle/working/trained_model/README.md (deflated 66%)\nupdating: kaggle/working/trained_model/adapter_model.safetensors (deflated 7%)\nupdating: kaggle/working/trained_model/tokenizer.json (deflated 70%)\nupdating: kaggle/working/trained_model/wandb_config.yaml (deflated 61%)\nupdating: kaggle/working/trained_model/tokenizer_config.json (deflated 76%)\nupdating: kaggle/working/trained_model/adapter_config.json (deflated 52%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We check for GPU availability using PyTorch. If a GPU is available, it is set as the device; otherwise, the CPU is used. This ensures that the model will leverage GPU acceleration if possible, enhancing training and inference speed.\n\nThe model is then moved to the selected device (GPU or CPU), allowing it to perform computations on the appropriate hardware. This step is crucial for optimizing performance, especially during model training and evaluation.","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Moving the model to GPU if available\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:30:48.048427Z","iopub.execute_input":"2024-10-27T19:30:48.049300Z","iopub.status.idle":"2024-10-27T19:30:48.191513Z","shell.execute_reply.started":"2024-10-27T19:30:48.049246Z","shell.execute_reply":"2024-10-27T19:30:48.190590Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (key): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (value): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=9, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"The model evaluation function computes the loss and accuracy on a given dataset. It uses a `DataLoader` to handle batching and leverages GPU for efficient computation. The evaluation process involves iterating through the dataset, predicting labels, and calculating the loss while ignoring special tokens.\n\nThe function tracks the total loss, correct predictions, and total predictions throughout the evaluation process. It also utilizes the `tqdm` library for visual progress updates and measures the total evaluation time.\n\nFinally, the average loss and accuracy are calculated and displayed for both the training and test datasets, providing insights into the model's performance.","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\ndef evaluate_model(model, dataset, data_collator, batch_size=16):\n    dataloader = DataLoader(dataset, collate_fn=data_collator, batch_size=batch_size)\n    \n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    # Visualization using tqdm and tracking time\n    start_time = time.time()\n    for batch in tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\"):\n        # Moving data to GPU\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n\n        with torch.no_grad():\n            outputs = model(**inputs, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n            # Calculating Loss\n            total_loss += loss.item()\n\n            # Calculating Accuracy\n            predictions = torch.argmax(logits, dim=-1)\n            mask = labels != -100  # Ignoring special tokens\n            correct_predictions += (predictions[mask] == labels[mask]).sum().item()\n            total_predictions += mask.sum().item()\n\n    # Calculating average loss and accuracy\n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_predictions * 100\n\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n    print(f\"Evaluation completed in {elapsed_time:.2f} seconds.\")\n    \n    return avg_loss, accuracy\n\n# Performing calculations for the training and test sets\ntrain_loss, train_accuracy = evaluate_model(model, train_dataset, data_collator)\nprint(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n\ntest_loss, test_accuracy = evaluate_model(model, test_dataset, data_collator)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:30:48.192601Z","iopub.execute_input":"2024-10-27T19:30:48.192912Z","iopub.status.idle":"2024-10-27T19:32:06.205920Z","shell.execute_reply.started":"2024-10-27T19:30:48.192879Z","shell.execute_reply":"2024-10-27T19:32:06.204912Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 233/233 [01:02<00:00,  3.73batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Evaluation completed in 62.44 seconds.\nTrain Loss: 0.0599, Train Accuracy: 98.29%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 58/58 [00:15<00:00,  3.73batch/s]","output_type":"stream"},{"name":"stdout","text":"Evaluation completed in 15.56 seconds.\nTest Loss: 0.0601, Test Accuracy: 98.36%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The evaluation results showed that the model achieved an accuracy of 98% on both the training and test datasets. While this high level of accuracy indicates that the model performs exceptionally well, it also suggests that there may still be room for improvement. The model is not perfect, but it does not appear to be overfitted, as the performance is consistent across both datasets. This balance suggests a well-generalized model that can be effectively used for predicting mountain names in various scenarios. Further refinement and additional data could enhance its accuracy and robustness even more.","metadata":{}},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T19:38:04.197172Z","iopub.execute_input":"2024-10-27T19:38:04.197557Z","iopub.status.idle":"2024-10-27T19:38:05.880427Z","shell.execute_reply.started":"2024-10-27T19:38:04.197522Z","shell.execute_reply":"2024-10-27T19:38:05.879683Z"},"trusted":true},"execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.032 MB of 0.032 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▄█▂▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▄█▇▇▆▅▅▄▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▃▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▃▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>2920695406202880.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>699</td></tr><tr><td>train/grad_norm</td><td>1.97479</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0859</td></tr><tr><td>train_loss</td><td>1.61764</td></tr><tr><td>train_runtime</td><td>541.5028</td></tr><tr><td>train_samples_per_second</td><td>20.587</td></tr><tr><td>train_steps_per_second</td><td>1.291</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">valiant-water-20</strong> at: <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/bues1dcv' target=\"_blank\">https://wandb.ai/claire-zhuk-atom-space/mountain-recognition/runs/bues1dcv</a><br/> View project at: <a href='https://wandb.ai/claire-zhuk-atom-space/mountain-recognition' target=\"_blank\">https://wandb.ai/claire-zhuk-atom-space/mountain-recognition</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241027_192136-bues1dcv/logs</code>"},"metadata":{}}]},{"cell_type":"markdown","source":"The `wandb.finish()` function is called to properly close the current W&B run. This finalizes the logging process, ensuring that all metrics, visualizations, and configurations are uploaded to the W&B server. It is essential for maintaining the integrity of the logged data and for organizing the experiment tracking efficiently. By finishing the run, you also prevent potential data loss and allow for easy access to the results in the W&B dashboard.","metadata":{}}]}